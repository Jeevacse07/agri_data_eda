{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e8ee561-9ba5-466a-aca4-8e6ca9394ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Jeeva\\Course\\csv_file\\agri_capstone.csv\")\n",
    "\n",
    "# Ensure column names are correct\n",
    "df.columns = df.columns.str.strip().str.lower()  # Standardize column names\n",
    "\n",
    "df.columns = (\n",
    "    df.columns.str.lower()  # Convert to lowercase\n",
    "    .str.replace(r\"[()]\", \"\", regex=True)  # Remove parentheses\n",
    "    .str.replace(r\"\\s+\", \"_\", regex=True)  # Replace spaces with underscores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b4f6c1b-b670-411d-99fb-452c579e5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional renaming for crop-related columns\n",
    "df.columns = df.columns.str.replace(\"_area_1000_ha\", \"_crop_area\", regex=True)\n",
    "df.columns = df.columns.str.replace(\"_production_1000_tons\", \"_crop_production\", regex=True)\n",
    "df.columns = df.columns.str.replace(\"_yield_kg_per_ha\", \"_crop_yield\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83be4d78-8dbe-48ed-8f36-cad81865470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dist_code', 'year', 'state_code', 'state_name', 'dist_name',\n",
       "       'rice_crop_area', 'rice_crop_production', 'rice_crop_yield',\n",
       "       'wheat_crop_area', 'wheat_crop_production', 'wheat_crop_yield',\n",
       "       'kharif_sorghum_crop_area', 'kharif_sorghum_crop_production',\n",
       "       'kharif_sorghum_crop_yield', 'rabi_sorghum_crop_area',\n",
       "       'rabi_sorghum_crop_production', 'rabi_sorghum_crop_yield',\n",
       "       'sorghum_crop_area', 'sorghum_crop_production', 'sorghum_crop_yield',\n",
       "       'pearl_millet_crop_area', 'pearl_millet_crop_production',\n",
       "       'pearl_millet_crop_yield', 'maize_crop_area', 'maize_crop_production',\n",
       "       'maize_crop_yield', 'finger_millet_crop_area',\n",
       "       'finger_millet_crop_production', 'finger_millet_crop_yield',\n",
       "       'barley_crop_area', 'barley_crop_production', 'barley_crop_yield',\n",
       "       'chickpea_crop_area', 'chickpea_crop_production', 'chickpea_crop_yield',\n",
       "       'pigeonpea_crop_area', 'pigeonpea_crop_production',\n",
       "       'pigeonpea_crop_yield', 'minor_pulses_crop_area',\n",
       "       'minor_pulses_crop_production', 'minor_pulses_crop_yield',\n",
       "       'groundnut_crop_area', 'groundnut_crop_production',\n",
       "       'groundnut_crop_yield', 'sesamum_crop_area', 'sesamum_crop_production',\n",
       "       'sesamum_crop_yield', 'rapeseed_and_mustard_crop_area',\n",
       "       'rapeseed_and_mustard_crop_production',\n",
       "       'rapeseed_and_mustard_crop_yield', 'safflower_crop_area',\n",
       "       'safflower_crop_production', 'safflower_crop_yield', 'castor_crop_area',\n",
       "       'castor_crop_production', 'castor_crop_yield', 'linseed_crop_area',\n",
       "       'linseed_crop_production', 'linseed_crop_yield', 'sunflower_crop_area',\n",
       "       'sunflower_crop_production', 'sunflower_crop_yield',\n",
       "       'soyabean_crop_area', 'soyabean_crop_production', 'soyabean_crop_yield',\n",
       "       'oilseeds_crop_area', 'oilseeds_crop_production', 'oilseeds_crop_yield',\n",
       "       'sugarcane_crop_area', 'sugarcane_crop_production',\n",
       "       'sugarcane_crop_yield', 'cotton_crop_area', 'cotton_crop_production',\n",
       "       'cotton_crop_yield'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of columns to drop (since they lack production and yield data)\n",
    "cols_to_drop = [\n",
    "    \"fruits_area_1000_ha\",\n",
    "    \"vegetables_area_1000_ha\",\n",
    "    \"fruits_and_vegetables_area_1000_ha\",\n",
    "    \"potatoes_area_1000_ha\",\n",
    "    \"onion_area_1000_ha\",\n",
    "    \"fodder_area_1000_ha\"\n",
    "]\n",
    "\n",
    "# Drop them from the DataFrame\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\") \n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e549c3fb-6253-4096-bdef-10d899646619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop: minor_pulses, Zero Rows: 552\n",
      "Crop: sesamum, Zero Rows: 1801\n",
      "Crop: castor, Zero Rows: 10231\n",
      "Crop: sunflower, Zero Rows: 10863\n",
      "Crop: groundnut, Zero Rows: 3748\n",
      "Crop: chickpea, Zero Rows: 1956\n",
      "Crop: kharif_sorghum, Zero Rows: 4520\n",
      "Crop: safflower, Zero Rows: 12571\n",
      "Crop: barley, Zero Rows: 8033\n",
      "Crop: rice, Zero Rows: 1079\n",
      "Crop: sorghum, Zero Rows: 4234\n",
      "Crop: cotton, Zero Rows: 7341\n",
      "Crop: oilseeds, Zero Rows: 1184\n",
      "Crop: pearl_millet, Zero Rows: 5817\n",
      "Crop: soyabean, Zero Rows: 11735\n",
      "Crop: rabi_sorghum, Zero Rows: 11999\n",
      "Crop: finger_millet, Zero Rows: 9958\n",
      "Crop: wheat, Zero Rows: 2283\n",
      "Crop: maize, Zero Rows: 1792\n",
      "Crop: pigeonpea, Zero Rows: 2790\n",
      "Crop: sugarcane, Zero Rows: 2028\n",
      "Crop: rapeseed_and_mustard, Zero Rows: 3744\n",
      "Crop: linseed, Zero Rows: 8314\n"
     ]
    }
   ],
   "source": [
    "# Define the common columns that should be retained in every crop DataFrame\n",
    "common_columns = {\"dist_code\", \"year\", \"state_code\", \"state_name\", \"dist_name\"}\n",
    "\n",
    "# Identify unique crop names dynamically (remove common columns)\n",
    "crop_names = set(col.split(\"_crop_\")[0] for col in df.columns if \"_crop_\" in col)\n",
    "\n",
    "# Dictionary to store DataFrames for each crop\n",
    "crop_dfs = {}\n",
    "\n",
    "for crop in crop_names:\n",
    "    # Select common columns + the current crop's specific columns\n",
    "    crop_columns = list(common_columns) + [f\"{crop}_crop_area\", f\"{crop}_crop_production\", f\"{crop}_crop_yield\"]\n",
    "\n",
    "    # Ensure the required columns exist in the DataFrame before filtering\n",
    "    existing_columns = [col for col in crop_columns if col in df.columns]\n",
    "\n",
    "    # Create a new DataFrame for the current crop\n",
    "    crop_dfs[crop] = df[existing_columns].copy()\n",
    "\n",
    "# Now crop_dfs dictionary contains separate DataFrames for each crop\n",
    "\n",
    "for crop, crop_df in crop_dfs.items():\n",
    "    zero_mask = (crop_df[f\"{crop}_crop_area\"] == 0) & \\\n",
    "                (crop_df[f\"{crop}_crop_production\"] == 0) & \\\n",
    "                (crop_df[f\"{crop}_crop_yield\"] == 0)\n",
    "    \n",
    "    zero_count = zero_mask.sum()\n",
    "    \n",
    "    print(f\"Crop: {crop}, Zero Rows: {zero_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e707c698-78be-4867-91f4-3cde0fabee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rice data saved successfully to 'rice_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "common_columns = ['dist_code', 'year', 'state_code', 'state_name', 'dist_name']\n",
    "rice_columns = ['rice_crop_area', 'rice_crop_production', 'rice_crop_yield']\n",
    "\n",
    "# Select rice-related data\n",
    "df_rice = df[common_columns + rice_columns]\n",
    "\n",
    "# Remove rows where all three rice production columns are zero\n",
    "df_rice = df_rice[~((df_rice['rice_crop_area'] == 0) & \n",
    "                     (df_rice['rice_crop_production'] == 0) & \n",
    "                     (df_rice['rice_crop_yield'] == 0))]\n",
    "\n",
    "# Save to Excel\n",
    "df_rice.to_excel(\"rice_data.xlsx\", index=False)\n",
    "\n",
    "print(\"Rice data saved successfully to 'rice_data.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38d427ee-0876-446a-8c94-f2d26107354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheat data saved successfully to 'wheat_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "common_columns = ['dist_code', 'year', 'state_code', 'state_name', 'dist_name']\n",
    "wheat_columns = ['wheat_crop_area', 'wheat_crop_production', 'wheat_crop_yield']\n",
    "\n",
    "# Select wheat-related data wheat_crop_area\n",
    "df_wheat = df[common_columns + wheat_columns]\n",
    "\n",
    "# Remove rows where all three wheat production columns are zero\n",
    "df_wheat = df_wheat[~((df_wheat['wheat_crop_area'] == 0) & \n",
    "                     (df_wheat['wheat_crop_production'] == 0) & \n",
    "                     (df_wheat['wheat_crop_yield'] == 0))]\n",
    "\n",
    "# Save to Excel\n",
    "df_wheat.to_excel(\"wheat_data.xlsx\", index=False)\n",
    "\n",
    "print(\"wheat data saved successfully to 'wheat_data.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f75e245-621e-4e3f-a19a-ad1c57b6a2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: minor_pulses_data.xlsx\n",
      "Saved: sesamum_data.xlsx\n",
      "Saved: castor_data.xlsx\n",
      "Saved: sunflower_data.xlsx\n",
      "Saved: groundnut_data.xlsx\n",
      "Saved: chickpea_data.xlsx\n",
      "Saved: kharif_sorghum_data.xlsx\n",
      "Saved: safflower_data.xlsx\n",
      "Saved: barley_data.xlsx\n",
      "Saved: rice_data.xlsx\n",
      "Saved: sorghum_data.xlsx\n",
      "Saved: cotton_data.xlsx\n",
      "Saved: oilseeds_data.xlsx\n",
      "Saved: pearl_millet_data.xlsx\n",
      "Saved: soyabean_data.xlsx\n",
      "Saved: rabi_sorghum_data.xlsx\n",
      "Saved: finger_millet_data.xlsx\n",
      "Saved: wheat_data.xlsx\n",
      "Saved: maize_data.xlsx\n",
      "Saved: pigeonpea_data.xlsx\n",
      "Saved: sugarcane_data.xlsx\n",
      "Saved: rapeseed_and_mustard_data.xlsx\n",
      "Saved: linseed_data.xlsx\n",
      "All crops have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define common columns (adjust if needed)\n",
    "common_columns = ['dist_code', 'year', 'state_code', 'state_name', 'dist_name']\n",
    "\n",
    "\n",
    "# Extract unique crop names dynamically\n",
    "crop_names = set(re.sub(r'_crop_(area|production|yield)$', '', col) for col in df.columns if col not in common_columns)\n",
    "\n",
    "# Writing each crop's data to a separate Excel file\n",
    "for crop in crop_names:\n",
    "    crop_columns = [f\"{crop}_crop_area\", f\"{crop}_crop_production\", f\"{crop}_crop_yield\"]\n",
    "    \n",
    "    # Ensure only existing columns are selected\n",
    "    crop_columns = [col for col in crop_columns if col in df.columns]\n",
    "\n",
    "    if crop_columns:  # Only proceed if valid columns exist\n",
    "        selected_columns = common_columns + crop_columns  # Use a list\n",
    "        crop_df = df[selected_columns]\n",
    "\n",
    "        # Save to an individual Excel file\n",
    "        file_name = f\"{crop}_data.xlsx\"\n",
    "        crop_df.to_excel(file_name, index=False)\n",
    "        print(f\"Saved: {file_name}\")\n",
    "\n",
    "print(\"All crops have been saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42c636b9-4e6c-4a93-abfd-5f2bcabbd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Unique Values\n",
    "unique_districts = df[['dist_code', 'dist_name', 'state_code', 'state_name']].drop_duplicates()\n",
    "unique_states = df[['state_code', 'state_name']].drop_duplicates()\n",
    "unique_years = df[['year']].drop_duplicates()\n",
    "\n",
    "# Save to Excel\n",
    "output_file = \"unique_values.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    unique_districts.to_excel(writer, sheet_name=\"Districts\", index=False)\n",
    "    unique_states.to_excel(writer, sheet_name=\"States\", index=False)\n",
    "    unique_years.to_excel(writer, sheet_name=\"Years\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a30c1291-e3ad-49b1-83be-abec7d1034d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
      "Installing collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1247d098-7417-4365-9a3b-783e914aab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Unique States & Save\n",
    "df_states = df[['state_code', 'state_name']].drop_duplicates()\n",
    "df_states.to_csv(\"states.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ac3e8c5-fda7-492b-82ac-5e2258c7754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Unique Districts & Save\n",
    "df_districts = df[['dist_code', 'dist_name', 'state_code']].drop_duplicates()\n",
    "df_districts.to_csv(\"districts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a80151a-5557-4144-b917-578a4f318128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root Tr%40de2win 127.0.0.1:3306 agri_capstone\n",
      "States inserted successfully.\n",
      "Districts inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Database credentials\n",
    "db_user = \"root\"\n",
    "db_password = \"Tr@de2win\"\n",
    "db_host = \"127.0.0.1:3306\"\n",
    "db_name = \"agri_capstone\"\n",
    "from urllib.parse import quote_plus\n",
    "db_password = quote_plus('Tr@de2win')  # Encode special characters\n",
    "\n",
    "print(db_user, db_password, db_host, db_name)\n",
    "# Correct connection using SQLAlchemy\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "\n",
    "\n",
    "# Insert Data\n",
    "df_states.to_sql('states', con=engine, if_exists='append', index=False)\n",
    "print(\"States inserted successfully.\")\n",
    "\n",
    "df_districts.to_sql('districts', con=engine, if_exists='append', index=False)\n",
    "print(\"Districts inserted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3459059c-84f3-401a-ab9f-b68e63dcd194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\jeeva\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2713108-cdb2-4112-989e-f29da9d6bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'minor_pulses', 'sesamum', 'castor', 'sunflower', 'groundnut', 'chickpea', 'kharif_sorghum', 'safflower', 'barley', 'rice', 'sorghum', 'cotton', 'oilseeds', 'pearl_millet', 'soyabean', 'rabi_sorghum', 'finger_millet', 'wheat', 'maize', 'pigeonpea', 'sugarcane', 'rapeseed_and_mustard', 'linseed'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract unique crop names dynamically\n",
    "import re\n",
    "crop_names = set(re.sub(r'_crop_(area|production|yield)$', '', col) for col in df.columns if col not in common_columns)\n",
    "print(crop_names)\n",
    "# Insert into MySQL (append to avoid overwriting)\n",
    "# Convert to DataFrame\n",
    "crop_df = pd.DataFrame({'crop_name': list(crop_names)})\n",
    "\n",
    "crop_df.to_sql('crops', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d20664-96ab-49b1-a59b-7abde69b3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "db_user = \"root\"\n",
    "db_password = \"Tr@de2win\"\n",
    "db_host = \"127.0.0.1:3306\"\n",
    "db_name = \"agri_capstone\"\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "db_password = quote_plus('Tr@de2win')  # Encode special characters\n",
    "\n",
    "# Correct connection using SQLAlchemy\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "\n",
    "# Load Excel file\n",
    "file_path = \"/mnt/data/wheat_data.xlsx\"\n",
    "df = pd.read_csv(r\"C:\\Jeeva\\Course\\csv_file\\agri_capstone.csv\")\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Read sheets into DataFrames\n",
    "df_states = pd.read_excel(xls, sheet_name=\"states\")\n",
    "df_districts = pd.read_excel(xls, sheet_name=\"districts\")\n",
    "df_crops = pd.read_excel(xls, sheet_name=\"crops\")\n",
    "df_crop_data = pd.read_excel(xls, sheet_name=\"crop_data\")\n",
    "\n",
    "# Insert into MySQL tables\n",
    "df_states.to_sql(\"states\", engine, if_exists=\"append\", index=False)\n",
    "df_districts.to_sql(\"districts\", engine, if_exists=\"append\", index=False)\n",
    "df_crops.to_sql(\"crops\", engine, if_exists=\"append\", index=False)\n",
    "df_crop_data.to_sql(\"crop_data\", engine, if_exists=\"append\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4971f5-86fc-4847-8faa-f7cc061c3836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating for barley with id 9\n",
      "updating for castor with id 3\n",
      "updating for chickpea with id 6\n",
      "updating for cotton with id 12\n",
      "updating for finger_millet with id 17\n",
      "updating for groundnut with id 5\n",
      "updating for kharif_sorghum with id 7\n",
      "updating for linseed with id 23\n",
      "updating for maize with id 19\n",
      "updating for minor_pulses with id 1\n",
      "updating for oilseeds with id 13\n",
      "updating for pearl_millet with id 14\n",
      "updating for pigeonpea with id 20\n",
      "updating for rabi_sorghum with id 16\n",
      "updating for rapeseed_and_mustard with id 22\n",
      "updating for rice with id 10\n",
      "updating for safflower with id 8\n",
      "Skipping sample_missing_data.xlsx - Crop ID not found.\n",
      "updating for sesamum with id 2\n",
      "updating for sorghum with id 11\n",
      "updating for soyabean with id 15\n",
      "updating for sugarcane with id 21\n",
      "updating for sunflower with id 4\n",
      "updating for wheat with id 18\n",
      "All files processed successfully.\n"
     ]
    }
   ],
   "source": [
    "CROP_MAPPING = {\n",
    "    \"minor_pulses\": 1, \"sesamum\": 2, \"castor\": 3, \"sunflower\": 4, \"groundnut\": 5,\n",
    "    \"chickpea\": 6, \"kharif_sorghum\": 7, \"safflower\": 8, \"barley\": 9, \"rice\": 10,\n",
    "    \"sorghum\": 11, \"cotton\": 12, \"oilseeds\": 13, \"pearl_millet\": 14, \"soyabean\": 15,\n",
    "    \"rabi_sorghum\": 16, \"finger_millet\": 17, \"wheat\": 18, \"maize\": 19, \"pigeonpea\": 20,\n",
    "    \"sugarcane\": 21, \"rapeseed_and_mustard\": 22, \"linseed\": 23\n",
    "}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database Connection (Modify accordingly)\n",
    "# Database connection details\n",
    "db_user = \"root\"\n",
    "db_password = \"Tr@de2win\"\n",
    "db_host = \"127.0.0.1:3306\"\n",
    "db_name = \"agri_capstone\"\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "db_password = quote_plus('Tr@de2win')  # Encode special characters\n",
    "\n",
    "# Correct connection using SQLAlchemy\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "\n",
    "# Crop ID Mapping\n",
    "CROP_MAPPING = {\n",
    "    \"minor_pulses\": 1, \"sesamum\": 2, \"castor\": 3, \"sunflower\": 4, \"groundnut\": 5,\n",
    "    \"chickpea\": 6, \"kharif_sorghum\": 7, \"safflower\": 8, \"barley\": 9, \"rice\": 10,\n",
    "    \"sorghum\": 11, \"cotton\": 12, \"oilseeds\": 13, \"pearl_millet\": 14, \"soyabean\": 15,\n",
    "    \"rabi_sorghum\": 16, \"finger_millet\": 17, \"wheat\": 18, \"maize\": 19, \"pigeonpea\": 20,\n",
    "    \"sugarcane\": 21, \"rapeseed_and_mustard\": 22, \"linseed\": 23\n",
    "}\n",
    "\n",
    "# Folder containing Excel files\n",
    "folder_path = \"C:\\\\Jeeva\\\\agridata\\\\\"\n",
    "\n",
    "# List all Excel files\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".xlsx\")]\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    # Extract crop name from filename (e.g., wheat_data.xlsx -> wheat)\n",
    "    crop_name = file.split(\"_data\")[0]\n",
    "\n",
    "    # Get crop_id from mapping\n",
    "    crop_id = CROP_MAPPING.get(crop_name.lower())\n",
    "    if crop_id is None:\n",
    "        print(f\"Skipping {file} - Crop ID not found.\")\n",
    "        continue\n",
    "\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Extract relevant columns dynamically\n",
    "    try:\n",
    "        df = df[[\"dist_code\", \"state_code\",\"year\",\n",
    "                 f\"{crop_name}_crop_area\",\n",
    "                 f\"{crop_name}_crop_production\",\n",
    "                 f\"{crop_name}_crop_yield\"]]\n",
    "    except KeyError as e:\n",
    "        print(f\"Skipping {file} - Missing expected columns: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Rename columns to match `crop_data` table\n",
    "    df.columns = [\"dist_code\",\"state_code\", \"year\", \"area_1000_ha\", \"production_1000_tons\", \"yield_kg_per_ha\"]\n",
    "\n",
    "    # Add crop_id column\n",
    "    df[\"crop_id\"] = crop_id\n",
    "    print(f\"updating for {crop_name} with id {crop_id}\")\n",
    "    # Insert into SQL table\n",
    "    df.to_sql(\"crop_data\", con=engine, if_exists=\"append\", index=False)\n",
    "\n",
    "print(\"All files processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49956222-0822-470c-a005-9712493f51c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
